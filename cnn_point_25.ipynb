{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 25, 25])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 25, 25])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Training\\Fault',\"25\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 25 and len(your_list[0]) == 25):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Training\\Non-Fault',\"25\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 25 and len(your_list[0]) == 25):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Testing\\Fault',\"25\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 25 and len(your_list[0]) == 25):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Testing\\Non-Fault',\"25\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 25 and len(your_list[0]) == 25):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d5f428a88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACDCAYAAACUaEA8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAL/UlEQVR4nO3df4wU9RnH8c9TBFRo5a6H9DyIp6lBbTWxnqZNGxNraMSmAaVt8I+GpjakSZuqMY1I04aatCUxNa2p/5BowcRoSiACjcZSatPWNMphrHICgi2WiwhcOWNBzkJ5+sdtYHe5ndnZmZ2Z7977lVx258fufOC5ffK9787OmrsLABCejxQdAADQGho4AASKBg4AgaKBA0CgaOAAECgaOAAEKlUDN7NbzWyPme0zsxVZhUKxqGvnoradxVo9D9zMpkh6U9ICScOStku6093faPSYnhkzvL+7u6Xj5eL06dpls2JytNn+0VGNHD8+4T+ulbp2dfV4X19/ZvmGhvZl9lzNmRKx7X+5pRg3PXLrtdfOa7jtwIH9Onp0pOEvbdLa9nR3e39f39kVJ0/WP2Fk1lKZElXj8tsxNDTi7rPr15+X4jlvlLTP3f8hSWb2tKRFkhq+0Pu7uzV4770pDtlmx47VLp9/fjE52mzgkUeiNieua19fvzZuHMws3/z5X0n5DElfrDMitr2fJkgLLo/c+txzv2q4beHCgbgnT1Tb/r4+DW7adHbF8HDtDiG9PmbNKjpBKjZ//tsTrU8zhdIn6UDV8nBlXe2BzZab2aCZDR45fjzF4ZCTxHUdHT2SWzikElvbmtfr0aO5hkNyaRr4RH8/nTMf4+5r3H3A3Qdmz4ga6aAkEte1q+ucv+xQTrG1rXm9lnm6E5LSTaEMS6qekJsr6Z10cVAC1LXE+vqippdi3ztIVNv3TkzX5p1np3Tmzq2d3vnMqZfjjoc2SzMC3y7pCjO7zMymSVoqaXM2sVAg6tq5qG2HaXkE7u6nzOx7kp7X+LtGj7v7UGbJUAjq2rmobedJM4Uid39W0rMZZUFJUNfORW07C5/EBIBA0cABIFA0cAAIFA0cAAKV6k1MoB3WrduS6vEzZybbf2Sk8baenujH1l8eJM7UqdHblyy5O9kTFimkj9Lv3Fl0grZgBA4AgaKBA0CgaOAAECjmwIES2bat8eViJelIxIUfV66MvZxsIqfe2qGRRWevfzV3R+01zf44cm2mx2unL8ZfJyZIjMABIFA0cAAIFA0cAALFHDhKZ+nSdI+fdt7p+J2qHDrSeBwzZ3b0c51OOAZ65plEuwORGIEDQKBo4AAQKBo4AASKOXAgR3csjpmfP3YsenvEhV4eeqiFQJPF9OlFJ2gLRuAAECgaOAAEigYOAIHKdw785Enp3XdzPWQiY2O1y1HXO467UDQQuJ6eHn3r9tvPLP/yeqvZHtIbaJ8Y8vidAsQIHAACRQMHgEDRwAEgUCFNY5VLmefy4yT9IsecPf10usfPnJlsXBL9nZjRz7V4caJDAZliBA4AgaKBA0CgaOAAECjmwIEU1q9Ptv/UqdFjplmzPha5Peo7MUdHk2VB+BiBA0CgaOAAEKjYBm5mj5vZYTPbWbWu28y2mtneym1Xe2Mia9S1c1HbyaOZOfC1kn4t6YmqdSskbXP31Wa2orJ8f/bx0EZrVdK6vrPM4neKMBa/S43LozZuCPIaGmvVhtres3Bh7YqIa5OXzapPpfudKqvYEbi7/1nS0brViyStq9xfJ4mPMwSGunYuajt5tDoHPsfdD0pS5fbiRjua2XIzGzSzwSMnTrR4OOSkpbqOjkacGoGyaKq2Na/X+qtzonTa/iamu69x9wF3H5h9wQXtPhxyUl3Xrq7ZRcdBRmper1GXU0YptHoe+CEz63X3g2bWK+lwlqFQGOpa57Ul+c6dXhiz/YOIbTF/31LbDtTqCHyzpGWV+8skbcomDgpGXTsXte1AzZxG+JSkv0mab2bDZnaXpNWSFpjZXkkLKssICHXtXNR28oidQnH3OxtsuiXjLMgRde1c1HbyyPVaKDsOjcke2pXnIROaUbd8vGbJf3BVflEmsY89mu7c60uSnp6c8rxzoCh8lB4AAkUDB4BAcTnZBMo9/ZPEh0UHiHTqVLrHx33+pP705pFfNJ6yubwn+rmSZj0v5hXXE3O8qG/ym/bgQLIwk8iqG24oOkIqP9m+fcL1jMABIFA0cAAIFA0cAAKV6xz49b0XavDb1+V5yGSOHatdrpsstZ+/nmMYtEv9HPnJk83vWy/rOfA0x/OMr3w7dOxSXfWXNWeW582r3f7e/myP104v68aiI7QFI3AACBQNHAACRQMHgEBxHngC/qOq+fu0JysXaOA3g0VHiPT9nctTPX7NwJr4nYAOwAgcAAJFAweAQNHAASBQzIGj4yz/w9ejd6g/GfvKKxvv+6fd6QMlEffeSsSJ5GuO/TPjMCg7RuAAECgaOAAEigYOAIFiDhzAhMbGhrV79/1nlnfvrr9Y+fv5BkrhSwteLjpCShN/7R8jcAAIFA0cAAJFAweAQOU6B/7v6ZfoiU8+mOchE5k5s3b5jsGVxQQBgCYwAgeAQNHAASBQNHAACFSuc+D/3b9D+5dNfD5jGXx6Q+2XCj5x5c8a7hv33YZldvSC3xcdIdIr30l3Pe+6rzKNNTLSeFvPV6Mfm/V3Ys6aFb09KuuJvw8kCxNrTNIbVctdddvDOQ+8UzECB4BA0cABIFCxDdzM5pnZC2a2y8yGzOzuyvpuM9tqZnsrt/V/X6HEqGtnoq6TSzMzuack3efur5jZRyXtMLOtkr4paZu7rzazFZJWSLo/4nlK77Ul5Z2fz9LY+M2kqeskk1ldr++eosEvV/X54eHaHeo/OFFituWnRUdoi9gRuLsfdPdXKvf/I2mXpD5JiyStq+y2TtLidoVE9qhrZ6Kuk0uiOXAz65d0naSXJM1x94PS+C+NpIsbPGa5mQ2a2eDxdFnRJmnrOjp6JK+oSCBtXY98+GFeUdGiphu4mc2UtEHSPe7e9PlD7r7G3QfcfWBGKwnRVlnUtatrdvsCoiVZ1HX29OntC4hMNHU2s5lN1fgvw5PuvrGy+pCZ9br7QTPrlXQ47nl6L7pIP77pptbTttmqLVuKjpCrrOqKcqGuk0czZ6GYpMck7XL3h6s2bZa0rHJ/maRN2cdDu1DXzkRdJ5dmRuCfl/QNSa+b2auVdSslrZb0WzO7S9K/JH2tPRHRJtS1M1HXSSS2gbv7X9Xo+3ykW7KNg7xQ185EXSeXgK/okb1VN99cuyLpRTUC8bsXXyw6ApCzV+N3CRAfpQeAQNHAASBQNHAACBRz4AAmNjoqrV9/ZvGDsbGazdPyzpOCX3NN0RFSsdcnXs8IHAACRQMHgEDRwAEgUDRwAAgUDRwAAkUDB4BA0cABIFDm7vkdzOyIpLcl9Ugaye3AyZQ5m5RNvkvdPbNvYaCumaCurStzvqyyTVjbXBv4mYOaDbr7QO4HbkKZs0nlzke21pU5X5mzSeXO1+5sTKEAQKBo4AAQqKIa+JqCjtuMMmeTyp2PbK0rc74yZ5PKna+t2QqZAwcApMcUCgAEigYOAIHKtYGb2a1mtsfM9pnZijyP3SDP42Z22Mx2Vq3rNrOtZra3cttVULZ5ZvaCme0ysyEzu7tM+eqyUtfmswVTV6lctaWu58qtgZvZFEmPSloo6WpJd5rZ1Xkdv4G1km6tW7dC0jZ3v0LStspyEU5Jus/dr5L0WUnfrfx/lSWfJOragiDqKpWytmtFXWu5ey4/kj4n6fmq5QckPZDX8SNy9UvaWbW8R1Jv5X6vpD1FZ6xk2SRpQdnyUdfOrGtZa0tda3/ynELpk3Sganm4sq5s5rj7QUmq3F5ccB6ZWb+k6yS9pPLlo64tKnldpTBqW7r/tzzrmmcDtwnWcQ5jDDObKWmDpHvc/f2i80yAurYggLpK1DaxvOuaZwMfljSvanmupHdyPH6zDplZryRVbg8XFcTMpmr8l+FJd99YtnwV1DWhQOoqhVHb0vy/FVHXPBv4dklXmNllZjZN0lJJm3M8frM2S1pWub9M43NZuTMzk/SYpF3u/nDVplLkq0JdEwiorlIYtS3F/1thdc15Yv82SW9KekvSD0vwRsNTkg5KOqnx0cZdkj6u8XeL91ZuuwvK9gWN/7n6mqRXKz+3lSUfde38upatttT13B8+Sg8AgeKTmAAQKBo4AASKBg4AgaKBA0CgaOAAECgaOAAEigYOAIH6P1+sABfCBJtmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d5f5517c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d5f7b9088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5900], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(625, 768)\n",
    "        self.fc2 = nn.Linear(768, 256)\n",
    "        self.fc3 = nn.Linear(256, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.684\n",
      "[1,  1200] loss: 0.671\n",
      "[1,  1800] loss: 0.658\n",
      "19.0490243434906 seconds\n",
      "[2,   600] loss: 0.636\n",
      "[2,  1200] loss: 0.617\n",
      "[2,  1800] loss: 0.601\n",
      "19.010209321975708 seconds\n",
      "[3,   600] loss: 0.578\n",
      "[3,  1200] loss: 0.563\n",
      "[3,  1800] loss: 0.545\n",
      "18.941499948501587 seconds\n",
      "[4,   600] loss: 0.526\n",
      "[4,  1200] loss: 0.518\n",
      "[4,  1800] loss: 0.509\n",
      "18.916609048843384 seconds\n",
      "[5,   600] loss: 0.495\n",
      "[5,  1200] loss: 0.488\n",
      "[5,  1800] loss: 0.485\n",
      "18.929553270339966 seconds\n",
      "[6,   600] loss: 0.476\n",
      "[6,  1200] loss: 0.469\n",
      "[6,  1800] loss: 0.464\n",
      "18.959420442581177 seconds\n",
      "[7,   600] loss: 0.460\n",
      "[7,  1200] loss: 0.456\n",
      "[7,  1800] loss: 0.453\n",
      "18.844926357269287 seconds\n",
      "[8,   600] loss: 0.447\n",
      "[8,  1200] loss: 0.448\n",
      "[8,  1800] loss: 0.441\n",
      "18.794151067733765 seconds\n",
      "[9,   600] loss: 0.440\n",
      "[9,  1200] loss: 0.436\n",
      "[9,  1800] loss: 0.436\n",
      "18.796140909194946 seconds\n",
      "[10,   600] loss: 0.430\n",
      "[10,  1200] loss: 0.430\n",
      "[10,  1800] loss: 0.430\n",
      "18.817049503326416 seconds\n",
      "[11,   600] loss: 0.424\n",
      "[11,  1200] loss: 0.427\n",
      "[11,  1800] loss: 0.422\n",
      "18.94149947166443 seconds\n",
      "[12,   600] loss: 0.418\n",
      "[12,  1200] loss: 0.422\n",
      "[12,  1800] loss: 0.417\n",
      "18.8031108379364 seconds\n",
      "[13,   600] loss: 0.416\n",
      "[13,  1200] loss: 0.413\n",
      "[13,  1800] loss: 0.414\n",
      "18.81605291366577 seconds\n",
      "[14,   600] loss: 0.408\n",
      "[14,  1200] loss: 0.414\n",
      "[14,  1800] loss: 0.409\n",
      "18.046447038650513 seconds\n",
      "[15,   600] loss: 0.409\n",
      "[15,  1200] loss: 0.407\n",
      "[15,  1800] loss: 0.407\n",
      "17.586471796035767 seconds\n",
      "[16,   600] loss: 0.403\n",
      "[16,  1200] loss: 0.405\n",
      "[16,  1800] loss: 0.401\n",
      "17.782624006271362 seconds\n",
      "[17,   600] loss: 0.402\n",
      "[17,  1200] loss: 0.398\n",
      "[17,  1800] loss: 0.400\n",
      "17.709927797317505 seconds\n",
      "[18,   600] loss: 0.397\n",
      "[18,  1200] loss: 0.397\n",
      "[18,  1800] loss: 0.397\n",
      "17.69897747039795 seconds\n",
      "[19,   600] loss: 0.396\n",
      "[19,  1200] loss: 0.393\n",
      "[19,  1800] loss: 0.395\n",
      "16.451476573944092 seconds\n",
      "[20,   600] loss: 0.390\n",
      "[20,  1200] loss: 0.396\n",
      "[20,  1800] loss: 0.391\n",
      "16.380788803100586 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_25.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[0.9921, 0.0079],\n",
      "        [0.9962, 0.0038],\n",
      "        [0.0133, 0.9867],\n",
      "        [0.9798, 0.0202],\n",
      "        [0.0069, 0.9931],\n",
      "        [0.9886, 0.0114],\n",
      "        [0.5519, 0.4481],\n",
      "        [0.0637, 0.9363],\n",
      "        [0.0101, 0.9899],\n",
      "        [0.2740, 0.7260]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  non_fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 87 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "87.67\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(625, 768)\n",
    "            self.fc2 = nn.Linear(768, 256)\n",
    "            self.fc3 = nn.Linear(256, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_25.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "87.72\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(625, 768)\n",
    "            self.fc2 = nn.Linear(768, 256)\n",
    "            self.fc3 = nn.Linear(256, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_25.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 7, 7])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 7, 7])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Training\\Fault',\"7\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 7 and len(your_list[0]) == 7):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Training\\Non-Fault',\"7\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 7 and len(your_list[0]) == 7):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Testing\\Fault',\"7\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 7 and len(your_list[0]) == 7):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Testing\\Non-Fault',\"7\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 7 and len(your_list[0]) == 7):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241b3b22c48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241b3c8e948>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241b3dc8788>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABoCAYAAADhAAsHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMxUlEQVR4nO3dfYwcdR3H8fe3PXot12sLLYWjLZXyUEolVDiKDZDaNEWpCIko1pCKT6kYmqCSGGNMAWN8SlSIGEiDRKkPxahoxYo2PgQ0orSVUigItbT0eogU8NpiH7j26x+zd+zN7t3Nzu7czP3u80o2Nzvzu93vfm7yvbnfzt6YuyMiIsPfqLwLEBGRxlBDFxEJhBq6iEgg1NBFRAKhhi4iEgg1dBGRQDTl9cRmYxyOz+vpa3BGjs+9ea+7n5TmO1vMfFKjy0molhNhT50+PdnArq5UtfRn56FD7D1yxNJ87/E5ZjtcvAip9l2z8Q6TsygpIC/0m22ihm5m7wLuAEYD97j7V2Pbm4H7gAuBV4APuPvOgR/1eOCyJE+fs59n/Pi/BT4DHAM+Any2bNuYXemyhUnAJxpeazLHahh766c/nWzggw+mquWhV17hpuee4yjw8bY2PjdzJgDtGzcC6fbdScCKVNWEZTvwENHP+wLg0rJtt0HKfXcy8PkMqg3JDbv62zLolIuZjQa+A1wBnAt80MzOjQ37GPCau58JfAv4WvpiR5KjwE3Ar4AtwP3AtvggZZvSUXdufPZZfnP++WybP58fv/QS215/PT5M+aZwDFgPXAfcCDwJvFw5TNkOsSRz6POB7e6+w92PAGuBq2Njrga+X1r+KbDYzFL9OTuyPEY0pTMLGANcS9Tc+1C2Kf193z7OHDeOWePGMWbUKJadfDK/3Ls3Pkz5prAHOBE4gejP9rnAM5XDlO0QS9LQpwG7y+53lNZVHePu3UAXmghLYA9QPoc8DeiMD1K2Ke05fJgZY8f23p/e3Myew4fjw5RvCvuBCWX3J5TWxSjbIZZkDr3ab9T4+15JxmBmK+idfhyX4KlDV+3tw4ooE2ULffOdWFddYUiUbop9V9kmfuM7RV84MX1RkugIvQOYUXZ/OpWHkb1jzKyJaJ9/Nf5A7r7a3dvdvT2aYhjpphNF12MP0BYflChb6JtvS+OLHXamNzez+9Ch3vsdhw9zanNzfFjN++5wODcraxOAfWX39wGtlcNS9IXxWZQ7YiRp6I8BZ5nZ6WY2BlgGrIuNWQdcX1p+H/AH179xTKCd6FyB54EjwE+AK+ODlG1KF7W28tzBgzx/8CBHjh1j7UsvcdWUKfFhyjeFaUSnrbxG9Nb+U8DsymHKdogNOuXi7t1mtpLo/LrRwL3u/pSZfRHY6O7rgO8Ca8xsO9Fv4GVZFh2OJuB24N1E5w1cT/T20q1EZ3oByja1plGjuPPss3nnli0cdeejbW3MbWlh1Y4d/Le7u2eY8k1hFLAU+AHRHMo8YCrwR+DUN4cp2yGW6Dx0d19PdJZS+bpVZcuHgPc3trSR4orSrdytvUvKtj5LJ09m6eS+78N9cdYs1r8a/eWvfNM7q3Qrt6hsWdkOvdw+KXoGXXyddB8WGUrX5F1ASodOvJDt796Yy3P/+9/Jx9rN3040zrt+kbKafixc2NjHk4Zo4wVWcEPeZRTabQNs0/9yEREJhBq6iEgg1NBFRAKhhi4iEgg1dBGRQKihi4gEQg1dRCQQaugiIoFQQxcRCYQauohIIHL76P/wUXHBCWkg/8YbeZdQsxeZyG3D4nq4eSr+v/UIkY7QRUQCoYYuIhIINXQRkUCooYuIBEINXUQkEIM2dDObYWZ/NLOnzewpM7upyph3mFmXmT1euq2q9lgS10l0Va7FwBLg3ooRyja93R0dLLrySuZcdBFzL76YO+66q2KM8k3rIPBX4E+l246KEcp26CU5bbEbuNndN5tZK7DJzDa4+7bYuEfcveIKxzKQJuALwFuBA8B7gMuovLCXsk2jqamJb3zpS1wwbx779+/nwoULWbJoEeeec058qPKtmQHnAhOJWsQjwElAa3ygsh1Cgx6hu/uL7r65tLwfeJroot9St6lEzRxgPHAGUMP122RAbaecwgXz5gHQ2trKnNmz2dOpzxU0xliiZg7Rgcl44FB+5QhQ4xy6mb0FeBvwtyqbF5jZFjP7jZnNbUBtI8xuYBvR9dMrKNs67dy1i3888QQXt7dX26x86/I/oAuYVG2jsh1CiT8pambjgZ8Bn3L3fbHNm4GZ7n7AzJYCv6DKvIGZrQBWAExJXfLQuoW3ZP4cR4DvEU22zOG83vWli8Emyhb65tvSclqGFQ8vBw4c4Jrly7n9K19hwoQJ8c0177swLtuCh5VuYBMwFzguvjFVtrexOMN6Q9D/p3ATHaGb2XFEzfyH7v7z+HZ33+fuB0rL64HjzKyiZ7v7andvd/f2ifGNI9RR4CfAecCcKtuTZlva3ptvc/NJmdU8nLzxxhtcs3w51117Le+96qqK7Wn2XRiTfeHDwjGiZj4NaKvYqmyHXpKzXAz4LvC0u3+znzGnlMZhZvNLj/tKIwsNkQPriP5aWdDPGGWbnrvzsZUrmTN7Np9ZubLqGOWblgNbiObOZ1UdoWyHXpIpl0uA5cBWM3u8tO7zwGkA7n438D7gk2bWTXQ+0zJ39wzqDcpu4Amit0bvLq1bTDQbWUbZpvSXRx9lzdq1nDd3LvMuvRSAL69axQu7d/Py3r09w5RvKq8Be4jOanm4tG42sTdGle0QG7Shu/ufic5RGmjMncCdjSpqpDgNuGWA7b9G2dbj0gUL8K6uqtvuue8+QPmmdyIw0NmIW5VtDvRJURGRQKihi4gEQg1dRCQQaugiIoFQQxcRCYQauohIINTQRUQCoYYuIhIINXQRkUCooYuIBEINXUQkEGroIiKBUEMXEQmEGrqISCDU0EVEAqGGLiISiMQXiZbh5dVXD7Jmzdacnv3FxCNtQ8WFhau7+bqUtfTn+QY/nkj+EjV0M9sJ7Ce6pnF3dDHXPtsNuANYCvwP+LC7b25sqWG6HWgmuiTUKHovfd5L2dbr90S7uZVul/XZqnzroWyLppYj9EXuvrefbVcAZ5VuFwN3lb5KAtcDx/e/WdnWbQEDXE1e+dZF2RZJo+bQrwbu88ijwCQza2vQY490yjZbyjc7ynaIJW3oDvzOzDaZWXxWAGAa0UXse3SU1skgDFgDrAY2VR+ibOv2KPAIsKvaRuVbF2VbJEmnXC5x904zmwpsMLNn3P3hsu1W5Xs8vqL0y2AFwJSaSw3TR4FW4HWixj4FmNl3SKJsoW++oAOhyCXAWOAwUfMZD0wuH1DzvgvjGlzjcKVsiybREbq7d5a+/gd4AJgfG9IBzCi7Px3orPI4q9293d3bJ6arNzitpa8twDnAnsohibKFvvnCCY0tdNgaW/raDJwC/Dc+oOZ9d4A54xFG2RbNoA3dzFrMrLVnGbgceDI2bB3wIYu8Hehy9+Tnro1QR4iObXqW/wVMrRymbFPrLt16lvfy5q/QXso3FWVbREmmXE4GHojOQKIJ+JG7P2RmNwC4+93AeqJTk7YTnZ70kWzKDcvrwP2l5WPAW4EzgY19hynb1A7zZppONH07lWi+t+dXqfJNZ6BseynbITZoQ3f3HcD5VdbfXbbswI2NLS18JwA3VFnfc5L/r1G29WkBFlZZPxN4AVC+6Q2ULcBWZZsDffRfRCQQuX30/1+cyTXcntfTJ3YLV+ZdwrCzZMnlicdu2PDPDCvJxtl0cRcP5l1GoS3Ou4ARSkfoIiKBUEMXEQmEGrqISCDU0EVEAqGGLiISCDV0EZFAqKGLiARCDV1EJBBq6CIigbDo3y3k8MRmL1P5X/GnEP3btlDU+3pmuvtJab5R+Q5K2Q4sl31X2SbSb7a5NfRqzGxj/ALUw1nRXk/R6qlXkV5PkWpphCK9niLV0ghZvh5NuYiIBEINXUQkEEVr6KvzLqDBivZ6ilZPvYr0eopUSyMU6fUUqZZGyOz1FGoOXURE0ivaEbqIiKRUmIZuZu8ys3+a2XYz+1ze9dTLzHaa2VYze9zMNg7+HZnWomyzrUf5ZleLsq3l8Ysw5WJmo4FngSVAB/AY8EF335ZrYXUws51Au7vnev6sss28FuWbXR3KtkZFOUKfD2x39x3ufgRYC1ydc02hULbZUr7ZUbY1KkpDnwbsLrvfUVo3nDnwOzPbZGYrcqxD2WZL+WZH2dYot4tEx1iVdfnPBdXnEnfvNLOpwAYze8bdH86hDmWbLeWbHWVbo6IcoXcAM8ruTwc6c6qlIdy9s/T1P8ADRH8+5kHZZkv5ZkfZ1qgoDf0x4CwzO93MxgDLgHU515SambWYWWvPMnA58GRO5SjbbCnf7CjbGhViysXdu81sJfBbYDRwr7s/lXNZ9TgZeMDMIMr4R+7+UB6FKNtsKd/sKNvaFeK0RRERqV9RplxERKROaugiIoFQQxcRCYQauohIINTQRUQCoYYuIhIINXQRkUCooYuIBOL/Q7WYOXHp3dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5800], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(49, 108)\n",
    "        self.fc2 = nn.Linear(108, 32)\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.fc4 = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.694\n",
      "[1,  1200] loss: 0.692\n",
      "[1,  1800] loss: 0.690\n",
      "3.8380799293518066 seconds\n",
      "[2,   600] loss: 0.689\n",
      "[2,  1200] loss: 0.688\n",
      "[2,  1800] loss: 0.687\n",
      "3.7066595554351807 seconds\n",
      "[3,   600] loss: 0.686\n",
      "[3,  1200] loss: 0.685\n",
      "[3,  1800] loss: 0.684\n",
      "3.7644057273864746 seconds\n",
      "[4,   600] loss: 0.684\n",
      "[4,  1200] loss: 0.683\n",
      "[4,  1800] loss: 0.682\n",
      "3.745497465133667 seconds\n",
      "[5,   600] loss: 0.681\n",
      "[5,  1200] loss: 0.681\n",
      "[5,  1800] loss: 0.680\n",
      "3.8390755653381348 seconds\n",
      "[6,   600] loss: 0.679\n",
      "[6,  1200] loss: 0.678\n",
      "[6,  1800] loss: 0.678\n",
      "5.213019371032715 seconds\n",
      "[7,   600] loss: 0.677\n",
      "[7,  1200] loss: 0.676\n",
      "[7,  1800] loss: 0.676\n",
      "6.118029594421387 seconds\n",
      "[8,   600] loss: 0.675\n",
      "[8,  1200] loss: 0.675\n",
      "[8,  1800] loss: 0.674\n",
      "6.090152978897095 seconds\n",
      "[9,   600] loss: 0.674\n",
      "[9,  1200] loss: 0.673\n",
      "[9,  1800] loss: 0.672\n",
      "6.086169481277466 seconds\n",
      "[10,   600] loss: 0.671\n",
      "[10,  1200] loss: 0.671\n",
      "[10,  1800] loss: 0.670\n",
      "6.1170337200164795 seconds\n",
      "[11,   600] loss: 0.669\n",
      "[11,  1200] loss: 0.668\n",
      "[11,  1800] loss: 0.668\n",
      "6.166815280914307 seconds\n",
      "[12,   600] loss: 0.668\n",
      "[12,  1200] loss: 0.666\n",
      "[12,  1800] loss: 0.666\n",
      "6.127986192703247 seconds\n",
      "[13,   600] loss: 0.666\n",
      "[13,  1200] loss: 0.663\n",
      "[13,  1800] loss: 0.664\n",
      "6.111059665679932 seconds\n",
      "[14,   600] loss: 0.662\n",
      "[14,  1200] loss: 0.662\n",
      "[14,  1800] loss: 0.662\n",
      "6.183740139007568 seconds\n",
      "[15,   600] loss: 0.660\n",
      "[15,  1200] loss: 0.660\n",
      "[15,  1800] loss: 0.659\n",
      "6.193696022033691 seconds\n",
      "[16,   600] loss: 0.658\n",
      "[16,  1200] loss: 0.658\n",
      "[16,  1800] loss: 0.656\n",
      "6.177766561508179 seconds\n",
      "[17,   600] loss: 0.655\n",
      "[17,  1200] loss: 0.655\n",
      "[17,  1800] loss: 0.655\n",
      "6.235512018203735 seconds\n",
      "[18,   600] loss: 0.654\n",
      "[18,  1200] loss: 0.653\n",
      "[18,  1800] loss: 0.652\n",
      "6.224560260772705 seconds\n",
      "[19,   600] loss: 0.650\n",
      "[19,  1200] loss: 0.651\n",
      "[19,  1800] loss: 0.650\n",
      "6.082187652587891 seconds\n",
      "[20,   600] loss: 0.649\n",
      "[20,  1200] loss: 0.648\n",
      "[20,  1800] loss: 0.647\n",
      "6.016477108001709 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_7.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[0.3973, 0.6027],\n",
      "        [0.3978, 0.6022],\n",
      "        [0.3758, 0.6242],\n",
      "        [0.4455, 0.5545],\n",
      "        [0.3906, 0.6094],\n",
      "        [0.5296, 0.4704],\n",
      "        [0.5286, 0.4714],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.4058, 0.5942],\n",
      "        [0.3355, 0.6645]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 85 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "70.26\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(49, 108)\n",
    "            self.fc2 = nn.Linear(108, 32)\n",
    "            self.fc3 = nn.Linear(32, 8)\n",
    "            self.fc4 = nn.Linear(8, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_7.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "71.49\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(49, 108)\n",
    "            self.fc2 = nn.Linear(108, 32)\n",
    "            self.fc3 = nn.Linear(32, 8)\n",
    "            self.fc4 = nn.Linear(8, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_7.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 50, 50])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 50, 50])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Training\\Fault',\"50\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 50 and len(your_list[0]) == 50):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Training\\Non-Fault',\"50\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 50 and len(your_list[0]) == 50):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Fault',\"50\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 50 and len(your_list[0]) == 50):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Non-Fault',\"50\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 50 and len(your_list[0]) == 50):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25666a2c388>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25666b527c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACECAYAAACJbXCEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALGklEQVR4nO3df6hc9ZnH8ffT/PC2TdtUY9KYZBslcWuwiBisJS6IS6HrWkt/mm5ZFASFRlBaqD8WVruwpbKg7pbdpRcs7UJhs0WLNhSKRAMNBTVppb9i6l1p0zSpuYVkG9fEmvjsHzNub+3k3jszZ84537nvF1zunDMz5zzMZ/KdJ997zpnITCRJ5XlT0wVIkgbjAC5JhXIAl6RCOYBLUqEcwCWpUA7gklSooQbwiPhgROyPiKmIuLOqotQscx1fZjteYtDjwCNiEfBz4APAQeAZ4FOZ+bPqylPdzHV8me34WTzEcy8HpjLzBYCI+E/gw8AZ3wwRSxPeMsQuVY2Xyfx9nOHOAXJ9Z8Ka6stUn35N5tEz5Qp9ZvuWiFxefZEawGH4bWae+8b1wwzga4BfzVg+CLzvjQ+KiJuBmztLbwb+Yohdqhrfm+3OAXI9D3i4suo0qI/N9YA5s52Z6zv4/4DVsC/AL3utH2YA7/VJ/yfzMZk5CUwCRCz3vP32GyDXi821DHNmOzPXzWvW5L233FJHXZrDF+65p+f6Yf6IeRBYN2N5LXBoiO2pHcx1fJntmBlmAH8G2BgR50fEUmAr8Fg1ZalB5jq+zHbMDDyFkpmnIuJW4LvAIuCrmfnTyipTI8x1fJnt+BlmDpzM/A7wnYpqUUuY6/jqJ9tjb17NIxf//Ygr0vxUPwcuSWrQUB24BHDZZRM8/fSfN13Ggnf55RNNl6Ca2YFLUqFq7cBXrtzA9dd/u85dqoft2zc3XYKkCtiBS1KhHMAlqVAO4JJUqFrnwNctOsS/LPe40qZ9f1G1Z08fPw67dlW6SQ3g+PGmK1Dd7MAlqVAeBy6pp+WvvMhHf3F/02VoFnbgklQoO3AN7W1LTnL1u/xWrqa9bcnJpktQzezAJalQduCSelu8GFasaLoKzcIOXJIKVWsHPvXyeVz37D/UuUv1MPWyl/qWxoEduCQVyjlwSb2ddRZs2NB0FZqFHbgkFcoBXJIK5QAuSYVyDlxDmz4+weTuTU2XseBNH/c7MRcaO3BJKlStHfiKFXDjjXXuUb38zMuWSGPBDlySClVrB+43t7SD39yi+di7/wSx5dmmy9As7MAlqVAO4JJUKAdwSSqUA7gkFcoBXJIKNedRKBGxDvgP4F3Aa8BkZv5zRJwNbAfWA78APpmZR+fcoed+tkKVuS5bBldcMdp6Nbdly6r/96p2m08Hfgr4XGZeBFwBbIuITcCdwM7M3Ajs7C6rHOY6nsx1AZmzH87Mw8Dh7u3jEbEPWAN8GLiq+7CvA7uAO0ZSpSpnruOpylwvW3mSPdc/N7JaNX/x5d7r+5oDj4j1wKXAU8Cq7pvl9TfNyjM85+aI2BMRe06cmO5nd6rJsLkePWqubTRsrtMnTtRVqgY07xnpiFgGPAzcnpm/i4h5PS8zJ4FJgPe+d3PeeusgZapKjz/+h9tV5PruiPz+JfN7nkbnpRm3q8h186pVWXmRqtS8OvCIWELnzfCNzHyku/rFiFjdvX81cGQ0JWpUzHU8mevCMZ+jUAJ4CNiXmffPuOsx4AbgS93fj46kQo2EuY6nKnPde2QJ8eV1I6lT1ZjPFMoW4G+BH0fE61e2uZvOG+G/IuIm4ADwidGUqBEx1/FkrgvIfI5C2Q2caQLtL6stR3Ux1/FkrguLZ2JKUqEcwCWpULWe2J4Jp07VuUf1kh4cpnl5FTjUdBGahR24JBXKS0tpaK8Cv2m6CPFq0wWodnbgklQoO3AN7bxLL+Xe3bubLmPB23HllU2XoJrZgUtSoRzAJalQDuCSVCjnwCX19Gcc4Q4ebLoMAdvOsN4OXJIKVWsHPjH1Ey689sI6d6keJg4cqHaDp0/DsWPVblP9O3266QpUMztwSSqUA7gkFcoBXJIKVesc+PSqi/m32/fUuUv1MH3f5qZLkFQBO3BJKpTHgWtoe3/0G2LNPzVdhiq+JuS5l1zCZ554otJtajDbzjmn53o7cEkqlAO4JBXKAVySCuUcuIZ2wQXr+OIXH2i6jAXv7ru/13QJqpkduCQVygFckgrlAC5Jhap1DvzVA3s5si3q3KV68NvLpfFgBy5Jhaq1A4/zLuNNt3gtlKbFV6q9FsoLL0yzdetXKt2mBjFd7eZeeQWmpqrdpiplBy5JhZr3AB4RiyLihxGxo7t8fkQ8FRHPR8T2iFg6ujI1KuY6nsx1YeinA78N2Ddj+T7ggczcCBwFbqqyMNXGXMeTuS4A85oDj4i1wF8D/wh8NiICuBr4m+5Dvg7cC/z7bNs5dGiKe+750MDFqiqdec2qclW7mOvCMd8O/EHg88Br3eVzgGOZeaq7fBBY0+uJEXFzROyJiD3w+6GKVeUqyvWl0VeqflSS67RfVN16c3bgEXEtcCQz90bEVa+v7vHQ7PX8zJwEJjvbWt7zMapf9bnuGEmd6sf/VJrrpk2b8weLLx9JparGfKZQtgDXRcQ1wATwdjqf8MsjYnH3U30tcGh0ZWoEzHU8mesCMucUSmbelZlrM3M9sBV4IjM/DTwJfLz7sBuAR0dWpSpnruPJXBeWYY4Dv4POH0im6MyxPVRNSWqYuY4ncx1DfZ2JmZm7gF3d2y8AfU2QrVixgY985Nv9PEUj8K1v/fGZmMPmqnYy1/HnmZiSVCi/kUdDe897NvC1r/k/q6bdeGO117h57jnYsqXSTapiduCSVKhaO/BMOHVq7sdptNKj8aWxYAcuSYVyAJekQjmAS1KhHMAlqVAO4JJUKI8Dl9RT5hQnT3r9/jazA5ekQtXaga9/6Sd8dfeFde5SPWx+6UCl23vrxGned9HvKt2m+vfWidNNl6Ca2YFLUqEiazwtLyKmgf8FflvbTvuzgvbWBtXV9+7MPLeC7QDmWgFzHVybs62ytp7Z1jqAA0TEnsys9qo7FWlzbdDu+qxtcG2ur821Qbvrq6M2p1AkqVAO4JJUqCYG8MkG9jlfba4N2l2ftQ2uzfW1uTZod30jr632OXBJUjWcQpGkQjmAS1KhahvAI+KDEbE/IqYi4s669jtLPesi4smI2BcRP42I27rrz46IxyPi+e7vdzZY46KI+GFE7Ogunx8RT3Vr2x4RS5uqbUaN5tp/ja3PFdqVrbn2VssAHhGLgH8F/grYBHwqIjbVse9ZnAI+l5kXAVcA27o13QnszMyNwM7uclNuA/bNWL4PeKBb21Hgpkaq6jLXgbU6V2hltubaS2aO/Ad4P/DdGct3AXfVse8+anwU+ACwH1jdXbca2N9QPWvpvCGvBnYAQeesrsW9XtOGajTXMcy1hGzNtfNT1xTKGuBXM5YPdte1QkSsBy4FngJWZeZhgO7vlQ2V9SDweeC17vI5wLHMfP1rodvwGppr/0rIFVqcrbn+QV0DePRY14rjFyNiGfAwcHtmtuKSehFxLXAkM/fOXN3joU2/hm2sCTDXCrSyLnP9Y3VdTvYgsG7G8lrgUE37PqOIWELnzfCNzHyku/rFiFidmYcjYjVwpIHStgDXRcQ1wATwdjqf8MsjYnH3U70Nr6G59qeUXKGF2Zrrn6qrA38G2Nj9q+xSYCvwWE377ikiAngI2JeZ98+46zHghu7tG+jMtdUqM+/KzLWZuZ7Oa/VEZn4aeBL4eJO1vYG59qGgXKFl2ZrrmXde1yT/NcDPgf8G/q6JPzS8oZ4r6fyX5kfAs92fa+jMXe0Enu/+PrvhOq8CdnRvXwA8DUwB3wTOasHraK5jmGvbsjXX3j+eSi9JhfJMTEkqlAO4JBXKAVySCuUALkmFcgCXpEI5gEtSoRzAJalQ/we5bgTXHoirqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25666c84848>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5800], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(2500, 1500)\n",
    "        self.fc2 = nn.Linear(1500, 640)\n",
    "        self.fc3 = nn.Linear(640, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.337\n",
      "[1,  1200] loss: 0.646\n",
      "[1,  1800] loss: 0.591\n",
      "60.850751638412476 seconds\n",
      "[2,   600] loss: 0.727\n",
      "[2,  1200] loss: 0.622\n",
      "[2,  1800] loss: 0.380\n",
      "60.59587574005127 seconds\n",
      "[3,   600] loss: 0.644\n",
      "[3,  1200] loss: 0.563\n",
      "[3,  1800] loss: 0.344\n",
      "60.57197976112366 seconds\n",
      "[4,   600] loss: 0.528\n",
      "[4,  1200] loss: 0.490\n",
      "[4,  1800] loss: 0.336\n",
      "60.611804485321045 seconds\n",
      "[5,   600] loss: 0.451\n",
      "[5,  1200] loss: 0.439\n",
      "[5,  1800] loss: 0.333\n",
      "60.97121334075928 seconds\n",
      "[6,   600] loss: 0.415\n",
      "[6,  1200] loss: 0.405\n",
      "[6,  1800] loss: 0.331\n",
      "60.578951358795166 seconds\n",
      "[7,   600] loss: 0.399\n",
      "[7,  1200] loss: 0.384\n",
      "[7,  1800] loss: 0.330\n",
      "60.59089708328247 seconds\n",
      "[8,   600] loss: 0.389\n",
      "[8,  1200] loss: 0.371\n",
      "[8,  1800] loss: 0.329\n",
      "60.45549249649048 seconds\n",
      "[9,   600] loss: 0.382\n",
      "[9,  1200] loss: 0.361\n",
      "[9,  1800] loss: 0.328\n",
      "60.56799817085266 seconds\n",
      "[10,   600] loss: 0.376\n",
      "[10,  1200] loss: 0.355\n",
      "[10,  1800] loss: 0.328\n",
      "61.17034387588501 seconds\n",
      "[11,   600] loss: 0.371\n",
      "[11,  1200] loss: 0.349\n",
      "[11,  1800] loss: 0.327\n",
      "60.92243456840515 seconds\n",
      "[12,   600] loss: 0.365\n",
      "[12,  1200] loss: 0.345\n",
      "[12,  1800] loss: 0.326\n",
      "60.890575647354126 seconds\n",
      "[13,   600] loss: 0.360\n",
      "[13,  1200] loss: 0.342\n",
      "[13,  1800] loss: 0.326\n",
      "55.88364934921265 seconds\n",
      "[14,   600] loss: 0.355\n",
      "[14,  1200] loss: 0.339\n",
      "[14,  1800] loss: 0.325\n",
      "60.67651653289795 seconds\n",
      "[15,   600] loss: 0.351\n",
      "[15,  1200] loss: 0.337\n",
      "[15,  1800] loss: 0.325\n",
      "60.86767768859863 seconds\n",
      "[16,   600] loss: 0.347\n",
      "[16,  1200] loss: 0.335\n",
      "[16,  1800] loss: 0.325\n",
      "60.384804487228394 seconds\n",
      "[17,   600] loss: 0.344\n",
      "[17,  1200] loss: 0.333\n",
      "[17,  1800] loss: 0.324\n",
      "60.35294699668884 seconds\n",
      "[18,   600] loss: 0.341\n",
      "[18,  1200] loss: 0.331\n",
      "[18,  1800] loss: 0.324\n",
      "60.35294556617737 seconds\n",
      "[19,   600] loss: 0.339\n",
      "[19,  1200] loss: 0.330\n",
      "[19,  1800] loss: 0.323\n",
      "60.514235734939575 seconds\n",
      "[20,   600] loss: 0.336\n",
      "[20,  1200] loss: 0.329\n",
      "[20,  1800] loss: 0.323\n",
      "60.60782265663147 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_50.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[6.9779e-01, 3.0221e-01],\n",
      "        [5.3358e-01, 4.6642e-01],\n",
      "        [1.3598e-03, 9.9864e-01],\n",
      "        [2.6577e-04, 9.9973e-01],\n",
      "        [6.1996e-04, 9.9938e-01],\n",
      "        [2.1236e-03, 9.9788e-01],\n",
      "        [1.0669e-03, 9.9893e-01],\n",
      "        [5.6985e-04, 9.9943e-01],\n",
      "        [9.4616e-05, 9.9991e-01],\n",
      "        [1.6085e-04, 9.9984e-01]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  non_fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 95 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "95.96\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(2500, 1500)\n",
    "            self.fc2 = nn.Linear(1500, 640)\n",
    "            self.fc3 = nn.Linear(640, 64)\n",
    "            self.fc4 = nn.Linear(64, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_50.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "95.9\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(2500, 1500)\n",
    "            self.fc2 = nn.Linear(1500, 640)\n",
    "            self.fc3 = nn.Linear(640, 64)\n",
    "            self.fc4 = nn.Linear(64, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_50.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

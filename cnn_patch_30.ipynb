{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 30, 30])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 30, 30])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Training\\Fault',\"30\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 30 and len(your_list[0]) == 30):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Training\\Non-Fault',\"30\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 30 and len(your_list[0]) == 30):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Fault',\"30\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 30 and len(your_list[0]) == 30):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Non-Fault',\"30\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 30 and len(your_list[0]) == 30):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221f2c5c588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221f2d81708>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221f2eb4888>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5800], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(900, 720)\n",
    "        self.fc2 = nn.Linear(720, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.431\n",
      "[1,  1200] loss: 0.637\n",
      "[1,  1800] loss: 0.851\n",
      "17.81845188140869 seconds\n",
      "[2,   600] loss: 0.707\n",
      "[2,  1200] loss: 0.616\n",
      "[2,  1800] loss: 0.659\n",
      "17.759711265563965 seconds\n",
      "[3,   600] loss: 0.693\n",
      "[3,  1200] loss: 0.597\n",
      "[3,  1800] loss: 0.594\n",
      "17.718892097473145 seconds\n",
      "[4,   600] loss: 0.669\n",
      "[4,  1200] loss: 0.571\n",
      "[4,  1800] loss: 0.560\n",
      "17.69399881362915 seconds\n",
      "[5,   600] loss: 0.636\n",
      "[5,  1200] loss: 0.547\n",
      "[5,  1800] loss: 0.534\n",
      "17.694995641708374 seconds\n",
      "[6,   600] loss: 0.603\n",
      "[6,  1200] loss: 0.524\n",
      "[6,  1800] loss: 0.510\n",
      "17.68503999710083 seconds\n",
      "[7,   600] loss: 0.574\n",
      "[7,  1200] loss: 0.503\n",
      "[7,  1800] loss: 0.489\n",
      "17.66313648223877 seconds\n",
      "[8,   600] loss: 0.549\n",
      "[8,  1200] loss: 0.484\n",
      "[8,  1800] loss: 0.471\n",
      "17.787103414535522 seconds\n",
      "[9,   600] loss: 0.526\n",
      "[9,  1200] loss: 0.467\n",
      "[9,  1800] loss: 0.456\n",
      "17.69200897216797 seconds\n",
      "[10,   600] loss: 0.507\n",
      "[10,  1200] loss: 0.453\n",
      "[10,  1800] loss: 0.442\n",
      "17.71391201019287 seconds\n",
      "[11,   600] loss: 0.490\n",
      "[11,  1200] loss: 0.441\n",
      "[11,  1800] loss: 0.431\n",
      "17.560587882995605 seconds\n",
      "[12,   600] loss: 0.476\n",
      "[12,  1200] loss: 0.430\n",
      "[12,  1800] loss: 0.421\n",
      "17.654174089431763 seconds\n",
      "[13,   600] loss: 0.463\n",
      "[13,  1200] loss: 0.421\n",
      "[13,  1800] loss: 0.413\n",
      "17.632272958755493 seconds\n",
      "[14,   600] loss: 0.452\n",
      "[14,  1200] loss: 0.413\n",
      "[14,  1800] loss: 0.406\n",
      "17.539679288864136 seconds\n",
      "[15,   600] loss: 0.442\n",
      "[15,  1200] loss: 0.406\n",
      "[15,  1800] loss: 0.399\n",
      "17.585477352142334 seconds\n",
      "[16,   600] loss: 0.434\n",
      "[16,  1200] loss: 0.400\n",
      "[16,  1800] loss: 0.394\n",
      "17.655171632766724 seconds\n",
      "[17,   600] loss: 0.426\n",
      "[17,  1200] loss: 0.395\n",
      "[17,  1800] loss: 0.389\n",
      "17.667117595672607 seconds\n",
      "[18,   600] loss: 0.419\n",
      "[18,  1200] loss: 0.390\n",
      "[18,  1800] loss: 0.384\n",
      "17.625303506851196 seconds\n",
      "[19,   600] loss: 0.413\n",
      "[19,  1200] loss: 0.385\n",
      "[19,  1800] loss: 0.381\n",
      "17.648201942443848 seconds\n",
      "[20,   600] loss: 0.408\n",
      "[20,  1200] loss: 0.382\n",
      "[20,  1800] loss: 0.377\n",
      "17.640236139297485 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_30.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[0.6356, 0.3644],\n",
      "        [0.6854, 0.3146],\n",
      "        [0.1409, 0.8591],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.0333, 0.9667],\n",
      "        [0.0648, 0.9352],\n",
      "        [0.0033, 0.9967],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.0021, 0.9979]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  non_fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 94 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "94.47\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(900, 720)\n",
    "            self.fc2 = nn.Linear(720, 128)\n",
    "            self.fc3 = nn.Linear(128, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_30.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "94.43333333333334\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(900, 720)\n",
    "            self.fc2 = nn.Linear(720, 128)\n",
    "            self.fc3 = nn.Linear(128, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_30.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

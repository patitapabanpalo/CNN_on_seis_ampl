{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 40, 40])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 40, 40])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Training\\Fault',\"40\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 40 and len(your_list[0]) == 40):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Training\\Non-Fault',\"40\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 40 and len(your_list[0]) == 40):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Fault',\"40\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 40 and len(your_list[0]) == 40):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Patch\\Testing\\Non-Fault',\"40\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 40 and len(your_list[0]) == 40):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aa237df248>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aa239045c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aa23a35788>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5800], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1600, 680)\n",
    "        self.fc2 = nn.Linear(680, 464)\n",
    "        self.fc3 = nn.Linear(464, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.370\n",
      "[1,  1200] loss: 0.643\n",
      "[1,  1800] loss: 0.763\n",
      "33.98319053649902 seconds\n",
      "[2,   600] loss: 0.711\n",
      "[2,  1200] loss: 0.612\n",
      "[2,  1800] loss: 0.554\n",
      "37.58332300186157 seconds\n",
      "[3,   600] loss: 0.694\n",
      "[3,  1200] loss: 0.577\n",
      "[3,  1800] loss: 0.499\n",
      "37.532550573349 seconds\n",
      "[4,   600] loss: 0.640\n",
      "[4,  1200] loss: 0.539\n",
      "[4,  1800] loss: 0.464\n",
      "37.49769687652588 seconds\n",
      "[5,   600] loss: 0.588\n",
      "[5,  1200] loss: 0.503\n",
      "[5,  1800] loss: 0.438\n",
      "37.4429407119751 seconds\n",
      "[6,   600] loss: 0.545\n",
      "[6,  1200] loss: 0.472\n",
      "[6,  1800] loss: 0.419\n",
      "37.403125047683716 seconds\n",
      "[7,   600] loss: 0.511\n",
      "[7,  1200] loss: 0.447\n",
      "[7,  1800] loss: 0.405\n",
      "37.83918642997742 seconds\n",
      "[8,   600] loss: 0.484\n",
      "[8,  1200] loss: 0.428\n",
      "[8,  1800] loss: 0.394\n",
      "38.18774890899658 seconds\n",
      "[9,   600] loss: 0.463\n",
      "[9,  1200] loss: 0.413\n",
      "[9,  1800] loss: 0.386\n",
      "37.88598442077637 seconds\n",
      "[10,   600] loss: 0.446\n",
      "[10,  1200] loss: 0.401\n",
      "[10,  1800] loss: 0.379\n",
      "37.76452326774597 seconds\n",
      "[11,   600] loss: 0.431\n",
      "[11,  1200] loss: 0.391\n",
      "[11,  1800] loss: 0.373\n",
      "37.67989659309387 seconds\n",
      "[12,   600] loss: 0.420\n",
      "[12,  1200] loss: 0.383\n",
      "[12,  1800] loss: 0.368\n",
      "37.79439043998718 seconds\n",
      "[13,   600] loss: 0.410\n",
      "[13,  1200] loss: 0.377\n",
      "[13,  1800] loss: 0.364\n",
      "37.635094165802 seconds\n",
      "[14,   600] loss: 0.401\n",
      "[14,  1200] loss: 0.372\n",
      "[14,  1800] loss: 0.360\n",
      "37.50168061256409 seconds\n",
      "[15,   600] loss: 0.394\n",
      "[15,  1200] loss: 0.367\n",
      "[15,  1800] loss: 0.357\n",
      "37.6898512840271 seconds\n",
      "[16,   600] loss: 0.387\n",
      "[16,  1200] loss: 0.363\n",
      "[16,  1800] loss: 0.354\n",
      "38.283236265182495 seconds\n",
      "[17,   600] loss: 0.382\n",
      "[17,  1200] loss: 0.359\n",
      "[17,  1800] loss: 0.352\n",
      "38.44950556755066 seconds\n",
      "[18,   600] loss: 0.377\n",
      "[18,  1200] loss: 0.356\n",
      "[18,  1800] loss: 0.350\n",
      "38.313103437423706 seconds\n",
      "[19,   600] loss: 0.372\n",
      "[19,  1200] loss: 0.353\n",
      "[19,  1800] loss: 0.348\n",
      "38.19562292098999 seconds\n",
      "[20,   600] loss: 0.368\n",
      "[20,  1200] loss: 0.351\n",
      "[20,  1800] loss: 0.346\n",
      "37.91585683822632 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_40.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[4.4028e-01, 5.5972e-01],\n",
      "        [5.5272e-01, 4.4728e-01],\n",
      "        [3.1718e-03, 9.9683e-01],\n",
      "        [3.5746e-02, 9.6425e-01],\n",
      "        [1.1017e-03, 9.9890e-01],\n",
      "        [1.5528e-04, 9.9984e-01],\n",
      "        [7.2322e-02, 9.2768e-01],\n",
      "        [1.0976e-03, 9.9890e-01],\n",
      "        [6.6414e-02, 9.3359e-01],\n",
      "        [3.2752e-03, 9.9672e-01]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 96 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "96.18666666666667\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(1600, 680)\n",
    "            self.fc2 = nn.Linear(680, 464)\n",
    "            self.fc3 = nn.Linear(464, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_40.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "95.93333333333334\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(1600, 680)\n",
    "            self.fc2 = nn.Linear(680, 464)\n",
    "            self.fc3 = nn.Linear(464, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_40.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

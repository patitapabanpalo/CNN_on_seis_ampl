{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training dataset and its labels\n",
      "torch.Size([20000, 21, 21])\n",
      "torch.Size([20000])\n",
      "the size of testing dataset and its labels\n",
      "torch.Size([6000, 21, 21])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "#the following codes reads the csv data files and converts them to trainloader and testloader\n",
    "\n",
    "original_directory = os.getcwd()\n",
    "TrainList = []\n",
    "LabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Training\\Fault',\"21\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 21 and len(your_list[0]) == 21):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Training\\Non-Fault',\"21\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 21 and len(your_list[0]) == 21):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TrainList.append(your_list)\n",
    "                    LabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "inputs = torch.FloatTensor(TrainList)\n",
    "#labellist = [0,0,1,1]\n",
    "labels = torch.tensor(LabelList, dtype=torch.long)\n",
    "train_data = []\n",
    "for i in range(len(inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    train_data.append([inputs[i], labels[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=10)\n",
    "print('the size of training dataset and its labels')\n",
    "print(inputs.shape);\n",
    "print(labels.shape);\n",
    "\n",
    "TestList = []\n",
    "OLabelList = []\n",
    "\n",
    "directory = os.path.join(r'Data_Point\\Testing\\Fault',\"21\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 21 and len(your_list[0]) == 21):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(1)\n",
    "            os.chdir(original_directory)\n",
    "            \n",
    "directory = os.path.join(r'Data_Point\\Testing\\Non-Fault',\"21\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            os.chdir(directory)\n",
    "            with open(file, 'r') as f:\n",
    "                reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "                your_list = list(reader)\n",
    "                if (len(your_list) == 21 and len(your_list[0]) == 21):\n",
    "                    #your_list = normalise_list(your_list,10)\n",
    "                    TestList.append(your_list)\n",
    "                    OLabelList.append(0)\n",
    "            os.chdir(original_directory)\n",
    "\n",
    "#print(TrainList[0])\n",
    "test_inputs = torch.FloatTensor(TestList)\n",
    "#labellist = [0,0,1,1]\n",
    "test_labels = torch.tensor(OLabelList, dtype=torch.long)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_inputs)):\n",
    "#    print(csvlabels[i])\n",
    "    test_data.append([test_inputs[i], test_labels[i]])\n",
    "    \n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=10)\n",
    "print('the size of testing dataset and its labels')\n",
    "print(test_inputs.shape);\n",
    "print(test_labels.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the two calsses of data for the labels 0 and 1 respectively \n",
    "\n",
    "classes = ('non_fault', 'fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14bd3f3da88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an seismic data\n",
    "print('three random examples of training fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[1200], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[1600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[8400], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three random examples of training non-fault data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14bd4066208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('three random examples of training non-fault data')\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(inputs[10800], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(inputs[14300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(inputs[17700], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four random examples of testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14bd41977c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAABqCAYAAABDCsEyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMCElEQVR4nO3dfWxV9R3H8fcXSy2tnchaXKVoEXFOMGHYKAZnMMaHuD/YYpiQmcmUYIxLptkfYpY42ZLhZrZlS4wbog6zTeeiTgJORbQTSba1CKIO5RkholBRLJTa4n774562915a7tN5uP3dzyu5uefp3vPNh5Mvp+fpmnMOERHxw6ikCxARkfCoqYuIeERNXUTEI2rqIiIeUVMXEfGImrqIiEdKaupmdp2ZvWdm281scVhFSYryjY6yjY6yTZYVe526mZ0CbAWuBvYB7cB859x/wyuvcinf6Cjb6Cjb5FWV8NlLgO3OuZ0AZvYkMAcY9h+vobratdTUlLDKiNTVJV3BgA0fftjpnGukwHzr6hrc2LEtsdWZbsyY7FoGhw8fzpzX0zM43NCQOe+dd8Kt60Qbiso2tUy1g9qoCxzBunGu1yimLzQ0uJazz46nzBFqw8aN/dtuTqU09QnA3rTxfcClJ/tAS00NHTNnlrDKiLS2Jl3BAFu6dE8wWFC+Y8e2cNttHVGWNqxp0zLHZ80aHF69OnPeu+8ODi9YkDlv6tQvQq3rRFVFZZtSC3wjkqr8sK5/oPC+cPbZdLz+ekR1+cHq6vbkXiqllGPqNsS0E47lmNkiM+sws46DfX0lrK7i5Mw3PdujRw/GVJYXCt52oTeGsrxQeF/o7IyhrMpRyp76PmBi2ngz8EH2Qs65ZcAyALOLnK35QwmrjIZrfTjpEoaSM9/0bFurq929y5P5E7Z3796M8c1pw9dnLXvL6NEDw/bAJ1lzYzs0V/C229rU5Dq+f1E81Y1ArY8N/JVYeLYzZugBVCEqZU+9HZhiZpPMrBqYB6wMpyxB+UZJ2UZH2Sas6D1159xxM/sB8CJwCvCocy7yU12VQvlGR9lGR9kmr5TDLzjnngeeD6kWyaJ8o6Nso6Nsk6U7SkVEPKKmLiLiETV1ERGPlHRM3Re2dHbSJaRZmnQBsbnsssw7eU87Ldr1rVkT7feLlAPtqYuIeERNXUTEI2rqIiIe0TF1X0ycCEuTOR5fnf6ULqD12WcHR668MnPh6dMHBpdnPUct6gd4Tp4c7fdLcTZs3InV3Zh0Gd7QnrqIiEfU1EVEPBLz4ZdPgWfiXWVe9PS92CxcODDY03dzxqzuuGspwKExE/jLtJ8nXUbZOjTmpaI/e/GkcXT8bF6I1fjHblqV97LaUxcR8YiauoiIR9TURUQ8oksaRfLQs2sDW7871C+1CUBP7kUkJtpTFxHxiJq6iIhHYj780gu8H+8q87Ir6QJEREKhPXUREY+oqYuIeERNXUTEI7EeU2/iAIv4XZyrzMsS7ki6hJJt2FmN3TgpobVfnTFWX3/vwHDXpjcy5rkVg09pnLF8eebX9ER8YVx7e9EfPetLX+K+WbNCLMYvq9avL/7DVVXQ2BheMRVOe+oiIh5RUxcR8YjuKAVgT9IFeMvd9aesKdOHXE5EwqE9dRERj+Rs6mb2qJkdMLO306aNM7M1ZrYteD8j2jJ99ibwEvDPgSnKNxy37NrF+I0bmfb2wKarbENyy+bNjF+7lmnr1g1MU7blIZ899T8C12VNWwysdc5NAdYG41KUZuDS7InKNwQLGhp44fzzsycr2xAsaG7mhdbW7MnKtgzkPKbunHvNzFqyJs8BZgfDK4A24O4Q64rVQ+T/qyJR+Bh4ELiXVdyemuRVvkm5or6e3Z9/nj1Z2YbginHj2N19wm9VKdsyUOwx9TOdc/sBgvfxwy1oZovMrMPMOsr558rKTF75pmeb+qlAyUNR2+7B3t7YChzBisv28OHYCqwEkZ8odc4tc861Oudaa6NeWYVJzxbGJl2Od9LzbayuTrocr2Rke/rpSZfjlWKb+kdm1gQQvB8IryRB+UZJ2UZH2ZaBYpv6SqD/p+BvBp4LpxwJKN/oKNvoKNsykPNEqZk9QerkR4OZ7QN+AtwPPGVmt5J6QPrcKIv02SPAVuAIcE9qUgPKNxTzd+ygrauLzuPHad60CZRtaOZv2kTboUN09vbS/MorVJmBsi0L+Vz9Mn+YWVeFXEtFujVr/HbodM59jPIt2ROTJ2eMW3u7sg3JE9Mz7wxuXb+e3ceOKdsyoMcEeOMzUjcxJSHzMQtdXYP3nNhvbspadn/a8D+y5tWEWtWJStjcGxth4cLwSvHN1q1Ff/SDbdu479prQyymsukxASIiHlFTFxHxSKyHX/YzjSWsjHOVeXmIc5MuwSv19YOHVbu63jjJkiISNu2pi4h4RE1dRMQjauoiIh7RJY3e6CPzcsE41SW0XhHJpj11ERGPqKmLiHgk1sMvtbWnMnXqpDhXmZfb219MuoQ0xd1ZdwEHeYwHQ64lP4eyxudxZyJ1iIj21EVEvKKmLiLiETV1ERGP6JJGCV1X19q0sdey5qb/GM5nWfPK99LIDTs+wW54OukyytgnSRcgAe2pi4h4RE1dRMQjsR5+6e7uor29Lc5V5mX06GuSLmFAX1/SFRTum/wt6RJkBDtrzBjuO++8pMsoa0veeivvZbWnLiLiETV1ERGPqKmLiHhElzRKCPZljR9NG34/a17nST5Xvpc0Xtwwio5vl299SWt9VvuH5UL/EiIiHlFTFxHxiA6/AH19Dyddwoi2mrsyxv+TNvyVrGWb04Y7WBVVSUNaEuvaRJKhPXUREY/k3FM3s4nA46R2uv4HLHPO/dbMxgF/BVqA3cB3nHN6AERBDgGPknoGigFXAKBsw3EY+DtwhFS6wHhQvmHYe+QI32tr48NjxxgFfBbcNadsk5fPnvpx4EfOua8BM4E7zOxCYDGw1jk3BVgbjEtBRgFzgZ8C9wCvAtSgbEMxCrgGuAO4NTVpvLbdcFSNGsWvZs5ky9y5/GvOHA4eO4ayLQ8599Sdc/sJftHYOddlZluACcAcYHaw2AqgDbg7kiq9NTZ4QaqXNwEHqiki23e5gMt4PJIqc1nNJYmsN5f64AVwaurtGNp2Q9FUW0tTbS0A9dXV1FRV8Xlvr7ItAwUdUzezFuDrwL+BM4OG39/4xw/zmUVm1mFmHak/iGVonQTXdB+hqGw/ja3SkShIp5Yit92DPT0xVTry7O7qovv4cSg229RnJSR5N3UzOw14GrjTOZf9IOxhOeeWOedanXOtcHoxNVaAHuD3wI2QOm+Rl8xsx+b+QIXqBZ5KDe4tdtttrKmJqLqR7UhfHze8/DIT6+ooOtsqXYQXJnPO5V7IbDSwCnjROffrYNp7wGzn3H4zawLanHNfzfE9B4E9QAOZtxZWMgPOA74AdgLnkDqDqmzDYcCFpDKpcc41lrDtHkXZpkvfdr8oMVttu0Prz+Qc51xjPh/I5+oXAx4BtvQ39MBK4Gbg/uD9uVzf1V+UmXWk9i4rW5DtCmAdcHl/Jmb2AMq2ZGn5NjvnJqbNKmrbVbaDhtt2UV8IVVGZOOdO+gIuBxywGdgUvK4Hvkzq7Pa24H1cru9K+86OfJf1+ZWVbbeyjSzf7jC2XWU7ZLbadqPNueBM8rn65XUGLvM9wVW5Pi/DS892iP+RlW2J+vMdZm9H+ZZA2275SuqO0mUJrbechZWJsj2Rso2W8o1OwZnkdaJURERGBj37RUTEI7E2dTO7zszeM7PtZlaRtw+b2UQze9XMtpjZO2b2w2D6ODNbY2bbgvczCvzeis8WlG+UlG10Qs02xrO4pwA7gHOBauBN4MKkzy4ncDa7CZgRDNcDW0ldR/1LYHEwfTHwC2WrfMvppWxHRrZx7qlfAmx3zu10zvUCT5J6TkRFcc7td869EQx3AenP0lkRLLYC+FYBX6tsA8o3Oso2OmFmG2dTnwDsTRvfF0yrWMU8S2cYynYIyjc6yjY6pWYbZ1Mf6lr3ir30pthn6Qz3dUNMq9hsQflGSdlGJ4xs42zq+4D0W7WbgQ9iXH/ZCJ6l8zTwZ+fcM8Hkj4JnZRC8HyjgK5VtGuUbHWUbnbCyjbOptwNTzGySmVUD80g9J6Ki5PEsHcjzmRlplG1A+UZH2UYn1GxjPsN7PamzujuAHyd9xjmJFxE8S0fZKl9lO7JfYWarO0pFRDyiO0pFRDyipi4i4hE1dRERj6ipi4h4RE1dRMQjauoiIh5RUxcR8YiauoiIR/4PiXh/m8gtKqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('four random examples of testing data')\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test_inputs[450], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test_inputs[2300], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test_inputs[4600], cmap=plt.cm.seismic)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test_inputs[5800], cmap=plt.cm.seismic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "        self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(441, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.0001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "#optimizer = optim.AdamW(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "#optimizer = optim.ASGD(net.parameters(), lr=0.0001, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.0001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "#optimizer = optim.Rprop(net.parameters(), lr=0.0001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.686\n",
      "[1,  1200] loss: 0.676\n",
      "[1,  1800] loss: 0.669\n",
      "11.222534894943237 seconds\n",
      "[2,   600] loss: 0.656\n",
      "[2,  1200] loss: 0.646\n",
      "[2,  1800] loss: 0.637\n",
      "13.323267698287964 seconds\n",
      "[3,   600] loss: 0.621\n",
      "[3,  1200] loss: 0.610\n",
      "[3,  1800] loss: 0.597\n",
      "13.27348780632019 seconds\n",
      "[4,   600] loss: 0.581\n",
      "[4,  1200] loss: 0.571\n",
      "[4,  1800] loss: 0.558\n",
      "13.395946979522705 seconds\n",
      "[5,   600] loss: 0.545\n",
      "[5,  1200] loss: 0.535\n",
      "[5,  1800] loss: 0.528\n",
      "13.33222770690918 seconds\n",
      "[6,   600] loss: 0.521\n",
      "[6,  1200] loss: 0.509\n",
      "[6,  1800] loss: 0.502\n",
      "13.403911352157593 seconds\n",
      "[7,   600] loss: 0.493\n",
      "[7,  1200] loss: 0.490\n",
      "[7,  1800] loss: 0.486\n",
      "13.229676008224487 seconds\n",
      "[8,   600] loss: 0.481\n",
      "[8,  1200] loss: 0.470\n",
      "[8,  1800] loss: 0.472\n",
      "13.241617679595947 seconds\n",
      "[9,   600] loss: 0.468\n",
      "[9,  1200] loss: 0.463\n",
      "[9,  1800] loss: 0.457\n",
      "13.204790353775024 seconds\n",
      "[10,   600] loss: 0.454\n",
      "[10,  1200] loss: 0.455\n",
      "[10,  1800] loss: 0.453\n",
      "13.3083336353302 seconds\n",
      "[11,   600] loss: 0.448\n",
      "[11,  1200] loss: 0.443\n",
      "[11,  1800] loss: 0.448\n",
      "13.110204458236694 seconds\n",
      "[12,   600] loss: 0.447\n",
      "[12,  1200] loss: 0.439\n",
      "[12,  1800] loss: 0.436\n",
      "13.036530017852783 seconds\n",
      "[13,   600] loss: 0.438\n",
      "[13,  1200] loss: 0.435\n",
      "[13,  1800] loss: 0.431\n",
      "13.05743932723999 seconds\n",
      "[14,   600] loss: 0.430\n",
      "[14,  1200] loss: 0.433\n",
      "[14,  1800] loss: 0.426\n",
      "13.029561996459961 seconds\n",
      "[15,   600] loss: 0.428\n",
      "[15,  1200] loss: 0.425\n",
      "[15,  1800] loss: 0.424\n",
      "13.079342365264893 seconds\n",
      "[16,   600] loss: 0.420\n",
      "[16,  1200] loss: 0.424\n",
      "[16,  1800] loss: 0.421\n",
      "13.164964199066162 seconds\n",
      "[17,   600] loss: 0.416\n",
      "[17,  1200] loss: 0.419\n",
      "[17,  1800] loss: 0.422\n",
      "13.243619680404663 seconds\n",
      "[18,   600] loss: 0.417\n",
      "[18,  1200] loss: 0.416\n",
      "[18,  1800] loss: 0.417\n",
      "13.162972211837769 seconds\n",
      "[19,   600] loss: 0.416\n",
      "[19,  1200] loss: 0.412\n",
      "[19,  1800] loss: 0.408\n",
      "13.066399574279785 seconds\n",
      "[20,   600] loss: 0.414\n",
      "[20,  1200] loss: 0.407\n",
      "[20,  1800] loss: 0.411\n",
      "13.190850496292114 seconds\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#train the network for 20 epochs\n",
    "\n",
    "for epoch in range(20): # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    t0 = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 600 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 600))\n",
    "            running_loss = 0.0\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network parameters\n",
    "\n",
    "PATH = './params/seismic_net_21.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted non fault and fault probabilities\n",
      "tensor([[0.4040, 0.5960],\n",
      "        [0.9737, 0.0263],\n",
      "        [0.3739, 0.6261],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.9673, 0.0327],\n",
      "        [0.1384, 0.8616],\n",
      "        [0.0134, 0.9866],\n",
      "        [0.0527, 0.9473],\n",
      "        [0.0243, 0.9757],\n",
      "        [0.9801, 0.0199]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted:  fault\n"
     ]
    }
   ],
   "source": [
    "#test sample data from testing\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "test_ips, labels = dataiter.next()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(test_ips)\n",
    "print('predicted non fault and fault probabilities')\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 91 %\n",
      "6000.0\n"
     ]
    }
   ],
   "source": [
    "#test the performance of the network on whole dataset\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        seis_data, labels = data\n",
    "        outputs = net(seis_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "91.53\n"
     ]
    }
   ],
   "source": [
    "#this part runs the code on GPU 10 times and reports the average accuracy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(441, 512)\n",
    "            self.fc2 = nn.Linear(512, 256)\n",
    "            self.fc3 = nn.Linear(256, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_21.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()[0].to(device), dataiter.next()[1].to(device)\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training for 1\n",
      "Finished Training for 2\n",
      "Finished Training for 3\n",
      "Finished Training for 4\n",
      "Finished Training for 5\n",
      "Finished Training for 6\n",
      "Finished Training for 7\n",
      "Finished Training for 8\n",
      "Finished Training for 9\n",
      "Finished Training for 10\n",
      "the avg acc is \n",
      "91.32000000000001\n"
     ]
    }
   ],
   "source": [
    "#this part is same code as above (runs 10 times and reports avg accuracy) but doesn't need GPU to run\n",
    "\n",
    "acc_list = []\n",
    "for j in range(10):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "            self.conv1 = nn.Conv2d(6, 16, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv1 = nn.Conv2d(16, 25, 3)\n",
    "            self.conv1 = nn.Conv2d(25, 32, 3)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(441, 512)\n",
    "            self.fc2 = nn.Linear(512, 256)\n",
    "            self.fc3 = nn.Linear(256, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, self.num_flat_features(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "    \n",
    "        def num_flat_features(self, x):\n",
    "            size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "            num_features = 1\n",
    "            for s in size:\n",
    "                num_features *= s\n",
    "            return num_features\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.0001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "    \n",
    "    for epoch in range(20): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        t0 = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print('Finished Training for %d'% (j+1))\n",
    "    \n",
    "    PATH = './seismic_net_21.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    dataiter = iter(testloader)\n",
    "    test_ips, labels = dataiter.next()\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    correct = 0.00\n",
    "    total = 0.00\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            seis_data, labels = data\n",
    "            outputs = net(seis_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accur = 100*(correct/total)\n",
    "    acc_list.append(accur)\n",
    "avg_acc = statistics.mean(acc_list)\n",
    "print (\"the avg acc is \")\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
